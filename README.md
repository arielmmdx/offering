# Arquitectura de Datalake/Datawarehouse en AWS

## Descripci√≥n del Proyecto

Este proyecto implementa una arquitectura completa de datalake y datawarehouse en AWS para el procesamiento de datos empresariales. La soluci√≥n incluye orquestaci√≥n con Apache Airflow, procesamiento de datos con Python y Spark, almacenamiento en S3, catalogado con AWS Glue, consultas con Athena, y visualizaci√≥n con Amazon QuickSight.

## üìÖ Cronograma del Proyecto

### **üöÄ Resumen del Cronograma**
- **Fecha de Inicio**: Lunes 25 de Agosto de 2025
- **Fecha de Finalizaci√≥n**: Viernes 31 de Octubre de 2025
- **Duraci√≥n Total**: 10 semanas (2.5 meses)

### **üìä Fases del Proyecto**

#### **üèóÔ∏è FASE 1: INFRAESTRUCTURA BASE (Semanas 1-5)**
- **Semana 1-2**: Configuraci√≥n AWS (25 Ago - 8 Sep)
- **Semana 3-4**: Construcci√≥n Data Lake (9 Sep - 22 Sep)
- **Semana 5**: Arquitectura de Almacenamiento (23 Sep - 6 Oct)

#### **üîÑ FASE 2: DESARROLLO ETL (Semanas 6-8)**
- **Semana 6**: Desarrollo ETL inicial - Recepci√≥n emails y extracci√≥n Excel (7 Oct - 13 Oct)
- **Semana 7**: Desarrollo ETL intermedio - Transformaci√≥n y catalogaci√≥n (14 Oct - 20 Oct)
- **Semana 8**: Desarrollo ETL final - Pipeline optimizado (21 Oct - 27 Oct)

#### **üß™ FASE 3: PRUEBAS Y DASHBOARD (Semanas 9-10)**
- **Semana 9**: Pruebas finales y ajustes (28 Oct - 30 Oct)
- **Semana 10**: Dashboard QuickSight y despliegue final (31 Oct)

### **üë• Equipo del Proyecto**
- **üèóÔ∏è Arquitecto Infraestructura**: Configuraci√≥n AWS, construcci√≥n del Data Lake, arquitectura de almacenamiento
- **üîß Arquitecto ETL**: Desarrollo completo del pipeline ETL, transformaciones y catalogaci√≥n
- **üìä Arquitecto Analytics**: Pruebas, validaci√≥n, dashboard QuickSight y despliegue final

### **üéØ Hitos del Proyecto**
- **üèÜ Hito 1**: 6 Octubre 2025 - Infraestructura AWS completamente configurada
- **üöÄ Hito 2**: 27 Octubre 2025 - Pipeline ETL funcionando y procesando datos
- **üéâ Hito 3**: 31 Octubre 2025 - Sistema completo en producci√≥n con dashboard activo

## Arquitectura del Sistema

### Diagrama de Arquitectura General

```mermaid
graph TB
    subgraph "ORIGEN DE DATOS"
        A[Email Forwarders] --> B[Casilla de Email]
        B --> C[Excel Attachments]
    end
    
    subgraph "ORQUESTACI√ìN"
        D[Apache Airflow<br/>EC2 t2.large<br/>Docker Compose]
    end
    
    subgraph "PROCESAMIENTO PYTHON"
        E[Python Container<br/>AWS ECR<br/>ECS Fargate]
    end
    
    subgraph "PROCESAMIENTO SPARK"
        F[Spark Container<br/>AWS ECR<br/>ECS Fargate]
    end
    
    subgraph "ALMACENAMIENTO S3"
        G[Landing Bucket<br/>empresa-datalake-landing-prod]
        H[Raw Bucket<br/>empresa-datalake-raw-prod]
        I[Master Bucket<br/>empresa-datalake-master-prod]
        J[Airflow Bucket<br/>empresa-datalake-airflow-prod]
        K[Athena Bucket<br/>empresa-datalake-athena-prod]
    end
    
    subgraph "CATALOGADO Y CONSULTAS"
        L[AWS Glue<br/>Data Catalog]
        M[Amazon Athena<br/>SQL Queries]
    end
    
    subgraph "VISUALIZACI√ìN"
        N[Amazon QuickSight<br/>Dashboards]
    end
    
    subgraph "MONITOREO"
        O[CloudWatch<br/>Logs & Metrics]
        P[Alertas y<br/>Notificaciones]
    end
    
    C --> D
    D --> E
    D --> F
    E --> G
    F --> H
    H --> I
    D --> J
    G --> L
    H --> L
    I --> L
    L --> M
    M --> N
    D --> O
    E --> O
    F --> O
    O --> P
    
    classDef email fill:#FF6B6B,stroke:#C92A2A,stroke-width:2px,color:#FFF
    classDef airflow fill:#FFA500,stroke:#E67700,stroke-width:2px,color:#FFF
    classDef python fill:#3776AB,stroke:#2E5A88,stroke-width:2px,color:#FFF
    classDef spark fill:#E25A1C,stroke:#B84A16,stroke-width:2px,color:#FFF
    classDef s3 fill:#FF9900,stroke:#E68900,stroke-width:2px,color:#FFF
    classDef aws fill:#232F3E,stroke:#1A2530,stroke-width:2px,color:#FFF
    classDef viz fill:#00A1F1,stroke:#0081C8,stroke-width:2px,color:#FFF
    classDef monitor fill:#FF6B6B,stroke:#C92A2A,stroke-width:2px,color:#FFF
    
    class A,B,C email
    class D airflow
    class E python
    class F spark
    class G,H,I,J,K s3
    class L,M aws
    class N viz
    class O,P monitor
```

### Flujo de Datos ETL

```mermaid
sequenceDiagram
    participant Email as Email Service
    participant Airflow as Apache Airflow
    participant Python as Python Container
    participant Spark as Spark Container
    participant Landing as Landing S3
    participant Raw as Raw S3
    participant Master as Master S3
    participant Glue as AWS Glue
    participant Athena as Athena
    participant QuickSight as QuickSight
    
    Note over Email,QuickSight: FLUJO ETL COMPLETO
    
    Email->>Airflow: Nuevo email con Excel
    Airflow->>Python: Ejecutar script de monitoreo
    Python->>Email: Descargar attachment
    Python->>Landing: Guardar Excel original
    
    Airflow->>Spark: Ejecutar transformaci√≥n
    Spark->>Landing: Leer Excel
    Spark->>Raw: Guardar datos en Parquet
    
    Airflow->>Spark: Ejecutar modelado
    Spark->>Raw: Leer datos raw
    Spark->>Master: Guardar tabl√≥n final
    
    Airflow->>Glue: Ejecutar crawler
    Glue->>Landing: Catalogar landing
    Glue->>Raw: Catalogar raw
    Glue->>Master: Catalogar master
    
    Athena->>Glue: Consultar metadatos
    Athena->>Master: Ejecutar consultas SQL
    
    QuickSight->>Athena: Obtener datos
    QuickSight->>QuickSight: Generar dashboards
```

### Arquitectura de Red y Seguridad

```mermaid
graph TB
    subgraph "INTERNET"
        A[Internet]
    end
    
    subgraph "VPC - 10.0.0.0/16"
        subgraph "PUBLIC SUBNET - 10.0.1.0/24"
            B[Internet Gateway]
            C[NAT Gateway]
            D[Apache Airflow<br/>EC2 t2.large]
        end
        
        subgraph "PRIVATE SUBNET - 10.0.2.0/24"
            E[Python ECS Tasks]
            F[Spark ECS Tasks]
        end
        
        subgraph "PRIVATE SUBNET - 10.0.3.0/24"
            G[RDS si aplica]
        end
        
        subgraph "SECURITY GROUPS"
            H[SG-Airflow<br/>Puertos: 22, 8080]
            I[SG-ECS<br/>Puertos: 80, 443]
            J[SG-Database<br/>Puerto: 5432]
        end
    end
    
    subgraph "AWS SERVICES"
        K[S3 Buckets]
        L[AWS Glue]
        M[Amazon Athena]
        N[QuickSight]
        O[CloudWatch]
    end
    
    A --> B
    B --> C
    C --> D
    D --> E
    D --> F
    E --> K
    F --> K
    D --> L
    D --> M
    M --> N
    D --> O
    E --> O
    F --> O
    
    classDef internet fill:#87CEEB,stroke:#4682B4,stroke-width:2px,color:#000
    classDef vpc fill:#F0F8FF,stroke:#4169E1,stroke-width:2px,color:#000
    classDef public fill:#98FB98,stroke:#32CD32,stroke-width:2px,color:#000
    classDef private fill:#FFB6C1,stroke:#DC143C,stroke-width:2px,color:#000
    classDef security fill:#FFD700,stroke:#FFA500,stroke-width:2px,color:#000
    classDef aws fill:#FF9900,stroke:#E68900,stroke-width:2px,color:#000
    
    class A internet
    class B,C,D,E,F,G vpc
    class D public
    class E,F,G private
    class H,I,J security
    class K,L,M,N,O aws
```

## Componentes Principales

### 1. Orquestaci√≥n - Apache Airflow
- **Ubicaci√≥n**: EC2 t2.large con Docker Compose
- **Funci√≥n**: Programaci√≥n y monitoreo de workflows ETL
- **Caracter√≠sticas**: 
  - Monitoreo de emails cada 1 hora
  - Ejecuci√≥n de tareas Python y Spark
  - Gesti√≥n de dependencias entre tareas
  - Alertas y notificaciones

### 2. Procesamiento Python
- **Contenedor**: Docker en AWS ECR
- **Orquestaci√≥n**: ECS Fargate
- **Funciones**:
  - Monitoreo de casilla de email
  - Descarga de attachments Excel
  - Ingesta en bucket Landing
  - Validaci√≥n de datos

### 3. Procesamiento Spark
- **Contenedor**: Docker con Java 11 y Spark 3.5.2
- **Orquestaci√≥n**: ECS Fargate
- **Funciones**:
  - Transformaci√≥n de datos Excel
  - Conversi√≥n a formato Parquet
  - Modelado de datos finales
  - Escritura en bucket Master

### 4. Almacenamiento S3
- **Landing**: Datos originales sin modificar (100GB)
- **Raw**: Datos transformados en Parquet (100GB)
- **Master**: Tablones finales modelados (100GB)
- **Airflow**: DAGs, configuraciones y logs (100GB)
- **Athena**: Resultados de consultas (100GB)

### 5. Catalogado y Consultas
- **AWS Glue**: Metadatos y cat√°logo de datos
- **Amazon Athena**: Consultas SQL sobre S3
- **Crawlers**: Catalogado autom√°tico de nuevos datos

### 6. Visualizaci√≥n
- **Amazon QuickSight**: Dashboards interactivos (2 usuarios iniciales)
- **Integraci√≥n**: Conexi√≥n directa con Athena
- **SPICE Storage**: 5GB para almacenamiento de datos

## Flujo de Email ETL

### Configuraci√≥n de Forwarders
1. **Email Principal**: `datos@empresa.com`
2. **Forwarders**: 
   - `forwarder1@empresa.com` ‚Üí Env√≠a Excel A
   - `forwarder2@empresa.com` ‚Üí Env√≠a Excel B
3. **Frecuencia**: Monitoreo cada 1 hora
4. **Procesamiento**: Autom√°tico con Airflow

### Pipeline de Datos
```
Email ‚Üí Python Script ‚Üí Landing S3 ‚Üí Spark Transform ‚Üí Raw S3 ‚Üí Spark Model ‚Üí Master S3 ‚Üí Glue Catalog ‚Üí Athena ‚Üí QuickSight
```

## Requisitos T√©cnicos

### EC2 t2.large
- **CPU**: 2 vCPUs
- **RAM**: 8 GB
- **Storage**: 50 GB EBS GP3
- **OS**: Amazon Linux 2 o Ubuntu 20.04

### Docker Compose
- **Airflow**: 2.8.0
- **PostgreSQL**: 13
- **Redis**: 7.2
- **Vol√∫menes**: DAGs, logs, config, plugins

### Contenedores ECS
- **Python**: 3.11-slim con dependencias
- **Spark**: 3.5.2 con Java 11
- **Recursos**: Configurables por tarea

## Monitoreo y Alertas

### CloudWatch
- **Logs**: Centralizaci√≥n de logs de todos los servicios
- **M√©tricas**: CPU, memoria, almacenamiento, latencia
- **Alertas**: Notificaciones por email/SMS
- **Dashboards**: Visualizaci√≥n de m√©tricas en tiempo real

### Airflow
- **Task Status**: Estado de cada tarea ETL
- **DAG Runs**: Historial de ejecuciones
- **SLA Monitoring**: Alertas por incumplimiento de SLAs
- **Email Notifications**: Notificaciones autom√°ticas

## Seguridad y Compliance

### IAM y Roles
- **Principle of Least Privilege**: Acceso m√≠nimo necesario
- **Service Roles**: Roles espec√≠ficos para cada servicio
- **Cross-Account Access**: Si se requiere multi-cuenta

### VPC y Networking
- **Private Subnets**: Para tareas ECS sensibles
- **Security Groups**: Restricci√≥n de tr√°fico
- **NAT Gateway**: Acceso controlado a internet

### Data Encryption
- **S3**: Encriptaci√≥n en reposo (AES-256)
- **Transit**: TLS 1.2+ para transferencias
- **KMS**: Gesti√≥n de claves de encriptaci√≥n

## Escalabilidad y Performance

### Auto-scaling
- **ECS Fargate**: Escalado autom√°tico basado en demanda
- **S3**: Escalado autom√°tico del almacenamiento
- **Athena**: Procesamiento paralelo de consultas

### Optimizaciones
- **Parquet**: Formato columnar para consultas eficientes
- **Partitioning**: Particionado por fecha en S3
- **Compression**: Compresi√≥n de datos para reducir costos

## Implementaci√≥n y Deployment

### Fases del Proyecto
1. **Setup AWS** (1-2 semanas)
2. **Infraestructura** (2-3 semanas)
3. **Desarrollo ETL** (4-6 semanas)
4. **Integraci√≥n** (2-3 semanas)
5. **Testing** (2-3 semanas)
6. **Deployment** (1-2 semanas)
7. **Capacitaci√≥n** (1 semana)
8. **Soporte Post-Implementaci√≥n** (1 mes)

### CI/CD Pipeline
- **GitHub Actions**: Automatizaci√≥n de despliegues
- **Docker Builds**: Construcci√≥n autom√°tica de im√°genes
- **Testing**: Pruebas autom√°ticas antes del despliegue
- **Rollback**: Capacidad de revertir cambios

## Documentaci√≥n y Capacitaci√≥n

### Documentaci√≥n T√©cnica
- **Arquitectura**: Diagramas y especificaciones t√©cnicas
- **Operaciones**: Runbooks y procedimientos
- **API**: Documentaci√≥n de interfaces
- **Troubleshooting**: Gu√≠as de resoluci√≥n de problemas
